---
title: "Case Study C - HIV"
author: "Oumaima Al Qoh, Francisco Arrieta, Lucia Camenisch, Manuela Giansante, Emily Schmidt, Camille Beatrice Valera"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true # creating a table of contents (toc)
    toc_float: 
      collapsed: false # toc does not collapse and is shown as a sidebar (toc_float)
    number_sections: true # document sections are numbered
    theme: cosmo
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = "center")
```

```{r packages}
library(data.table)
library(ggplot2)
library(e1071)
library(missForest)
library(caret)
library(MASS)
library(gridExtra)
library(fabletools)
library(forecast)
```

```{r}
aids <- fread("Caids.csv")

aids[, sex := as.factor(sex)]
aids[, type := as.factor(type)]

new_DF <- aids[rowSums(is.na(aids)) > 0,]
```


```{r}
par(mfrow = c(3,2))

hist(aids$cd4)
hist(sqrt(aids$cd4))
hist(aids$cd8)
hist(sqrt(aids$cd8))
hist(aids$rna)
hist(log(aids$rna))
```

```{r}
aids_melt <- melt(aids[, -1], id.vars = "type")
ggplot(data = aids_melt[type %in% "DP",], aes(value)) + geom_histogram() +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "DP")
ggplot(data = aids_melt[type %in% "CP",], aes(value)) + geom_histogram() +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "CP")
```


```{r}
cor(aids[, 3:5], use = "complete.obs")
```


```{r}
skewness(sqrt(aids$cd4), na.rm = TRUE)
skewness(sqrt(aids$cd8), na.rm = TRUE)
skewness(log(aids$rna), na.rm = TRUE)
```

```{r}
aids[, sex := ifelse(sex == "m", 0, 1)]
aids[, type := ifelse(type == "DP", 0, 1)]

plot(aids[, 3:5], col = aids$type)

summary(aids)
```


```{r}
aids_completed <- missForest(aids, variablewise = TRUE)

summary(aids)
summary(aids_completed$ximp)
```

```{r}
aids <- aids_completed$ximp
```

# emily's training and  test set
```{r}
# Partitioning into training (60%) and validation (40%) 
train.index <- sample(c(1:dim(aids)[1]), dim(aids)[1]*0.6)
test.index <- setdiff(c(1:dim(aids)[1]), train.index)  

# Collect all the columns with training rows into training set 
train <- aids[train.index, ]
test <- aids[test.index, ]
```


# pre-processing

```{r}
norm_values <- preProcess(train, method = c("center", "scale"))
norm_train <- predict(norm_values, train)

norm_values2 <- preProcess(test, method = c("center", "scale"))
norm_test <- predict(norm_values2, test)

```


```{r}
# Lambda per cd4
lambda<-BoxCox.lambda(aids[,c(3)], method = c("guerrero"))
BoxCox(aids$cd4, lambda = lambda)


```


# LDA (normal distributions)
 The method assumes that the data can be separated into classes based on linear combination of the input features.
If there is not separation in the data logit regression will out-perform LDA.
Coefficients of linear discriminants: These display the linear combination of predictor variables that are used to form the decision rule of the LDA model. 
However, unlike tree-based models, LDA assumes that the predictors are normally distributed and that the covariance matrices are equal for all classes, so the variable importance measures may not be appropriate for all types of data.

Equal covariance matrices assumption:
```{r}
plot <- list()
box_variables <- c("sex", "cd4", "cd8", "rna")
for(i in box_variables) {
    plot[[i]] <- ggplot(norm_train, 
                        aes_string(x = "type", 
                                   y = i, 
                                   col = "type", 
                                   fill = "type")) + 
    geom_boxplot(alpha = 0.2) + 
    theme(legend.position = "none") + 
    scale_color_manual(values = c("blue", "red")) +
    scale_fill_manual(values = c("blue", "red"))
}
do.call(grid.arrange, c(plot, nrow = 1))
```

Definitely not same covariance matrices.


```{r}
set.seed(1)

# Fit the model
DA1 <- lda(type ~., data= norm_train)
# the response variable is the grouping factor 
DA1
plot(DA1)
varplot(DA1)
importance<- as.data.frame(melt(DA1$scaling^2))
ggplot(importance) + geom_col(aes(x=Var1 ,y= value , fill= value), showlegend = F)+ theme_classic()

```

#QDA
- Observation of each class is drawn from a normal distribution (same as LDA).
- QDA assumes that each class has its own covariance matrix
```{r}
set.seed(1)

# Fit the model
DA2 <- qda(type ~., data= norm_train)
# the response variable is the grouping factor 
DA2

importance2<- as.data.frame(melt(DA2$scaling^2))
ggplot(importance2) + geom_col(aes(x=Var1 ,y= value , fill= Var1), showlegend = F)+ theme_classic()

```





# tree, bagging, boosting, random forests give importance

# logistic regression importance through coeffs



