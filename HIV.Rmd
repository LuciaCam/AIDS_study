---
title: "Case Study C - HIV"
author: "Oumaima Al Qoh, Francisco Arrieta, Lucia Camenisch, Manuela Giansante, Emily Schmidt, Camille Beatrice Valera"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true # creating a table of contents (toc)
    toc_float: 
      collapsed: false # toc does not collapse and is shown as a sidebar (toc_float)
    number_sections: true # document sections are numbered
    theme: cosmo
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.align = "center")
```

```{r packages}
library(data.table)
library(ggplot2)
library(e1071)
library(missForest)
library(caret)
library(MASS)
library(gridExtra)
library(fabletools)
```

```{r}
aids <- fread("Caids.csv")

aids[, sex := as.factor(sex)]
aids[, type := as.factor(type)]

new_DF <- aids[rowSums(is.na(aids)) > 0,]
```


```{r}
par(mfrow = c(3,2))

hist(aids$cd4)
hist(sqrt(aids$cd4))
hist(aids$cd8)
hist(sqrt(aids$cd8))
hist(aids$rna)
hist(log(aids$rna))
```

```{r}
aids_melt <- melt(aids[, -1], id.vars = "type")
ggplot(data = aids_melt[type %in% "DP",], aes(value)) + geom_histogram() +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "DP")
ggplot(data = aids_melt[type %in% "CP",], aes(value)) + geom_histogram() +
  facet_wrap(~ variable, scales = "free") +
  labs(title = "CP")
```


```{r}
cor(aids[, 3:5], use = "complete.obs")
```


```{r}
skewness(sqrt(aids$cd4), na.rm = TRUE)
skewness(sqrt(aids$cd8), na.rm = TRUE)
skewness(log(aids$rna), na.rm = TRUE)
```

```{r}
aids[, sex := ifelse(sex == "m", 0, 1)]
aids[, type := ifelse(type == "DP", 0, 1)]

plot(aids[, 3:5], col = aids$type)

summary(aids)
```


```{r}
aids_completed <- missForest(aids, variablewise = TRUE)

summary(aids)
summary(aids_completed$ximp)
```

```{r}
aids <- aids_completed$ximp
```



# pre-processing

```{r}
norm_values <- preProcess(aids, method = c("center", "scale"))
norm_aids <- predict(norm_values, aids)
```


## boxcox under lucia suggestion

It transforms a non-normal dependent variables into a normal shape.

```{r}
bcx_aids<- box_cox(aids, lambda=1)

```


# LDA (normal distributions)
 The method assumes that the data can be separated into classes based on linear combination of the input features.
If there is not separation in the data logit regression will out-perform LDA.
Coefficients of linear discriminants: These display the linear combination of predictor variables that are used to form the decision rule of the LDA model. 
However, unlike tree-based models, LDA assumes that the predictors are normally distributed and that the covariance matrices are equal for all classes, so the variable importance measures may not be appropriate for all types of data.

Equal covariance matrices assumption:
```{r}
plot <- list()
box_variables <- c("sex", "cd4", "cd8", "rna")
for(i in box_variables) {
    plot[[i]] <- ggplot(norm_aids, 
                        aes_string(x = "type", 
                                   y = i, 
                                   col = "type", 
                                   fill = "type")) + 
    geom_boxplot(alpha = 0.2) + 
    theme(legend.position = "none") + 
    scale_color_manual(values = c("blue", "red")) +
    scale_fill_manual(values = c("blue", "red"))
}
do.call(grid.arrange, c(plot, nrow = 1))
```

Definitely not same covariance matrices.


```{r}
set.seed(1)

# Fit the model
DA1 <- lda(type ~., data= norm_aids)
# the response variable is the grouping factor 
DA1
plot(DA1)
varplot(DA1)
importance<- as.data.frame(melt(DA1$scaling^2))
ggplot(importance) + geom_col(aes(x=Var1 ,y= value , fill= value), showlegend = F)+ theme_classic()

```

#QDA
- Observation of each class is drawn from a normal distribution (same as LDA).
- QDA assumes that each class has its own covariance matrix
```{r}
set.seed(1)

# Fit the model
DA2 <- qda(type ~., data= norm_aids)
# the response variable is the grouping factor 
DA2

importance2<- as.data.frame(melt(DA2$scaling^2))
ggplot(importance2) + geom_col(aes(x=Var1 ,y= value , fill= Var1), showlegend = F)+ theme_classic()

```





# tree, bagging, boosting, random forests give importance

# logistic regression importance through coeffs



